# [Lecture Notes] Categories of NLP Tasks

## 1. Fundamental Language Processing

### 1.1 Tokenization
- **Definition**: Splitting text into smaller units such as words, subwords, or characters.  
- **Example**:  
  - Input: `"I love natural language processing."`  
  - Output: `["I", "love", "natural", "language", "processing", "."]`  
- **Importance**: Serves as the first step of most NLP tasks by providing structured text units.

### 1.2 Morphological Analysis
- **Definition**: Identifying morphemes, which are the smallest meaningful units in a language.  
- **Example (Korean)**:  
  - Input: `"먹었습니다"`  
  - Output: `먹 (root: eat) + 었 (past tense) + 습니다 (formal polite ending)`  
- **Importance**: Especially crucial for agglutinative languages (Korean, Japanese) where words are formed by combining morphemes.

### 1.3 Part-of-Speech Tagging
- **Definition**: Assigning grammatical categories (noun, verb, adjective, etc.) to each token.  
- **Example**:  
  - Input: `"Dogs bark loudly."`  
  - Output: `[("Dogs", NNS), ("bark", VB), ("loudly", RB)]`  
- **Importance**: Provides syntactic information for higher-level NLP tasks such as parsing or information extraction.



## 2. Semantic & Information Extraction

### 2.1 Named Entity Recognition (NER)
- **Definition**: Identifying named entities such as people, organizations, locations, and dates.  
- **Example**:  
  - Input: `"Barack Obama was born in Hawaii."`  
  - Output: `[("Barack Obama", PERSON), ("Hawaii", LOCATION)]`

### 2.2 Parsing
- **Definition**: Analyzing the grammatical structure of a sentence and constructing parse trees.  
- **Example**:  
  - Input: `"The cat sat on the mat."`  
  - Output: A parse tree showing subject (cat), verb (sat), and object (mat).  
- **Types**:  
  - **Constituency Parsing**: Breaks down sentences into nested constituents.  
  - **Dependency Parsing**: Represents grammatical relations between words.

### 2.3 Sentiment Analysis
- **Definition**: Determining the emotional polarity (positive, negative, neutral) of text.  
- **Example**:  
  - Input: `"This movie is amazing!"`  
  - Output: Positive sentiment.  

### 2.4 Relation Extraction
- **Definition**: Identifying semantic relationships between entities.  
- **Example**:  
  - Input: `"Tim Cook is the CEO of Apple."`  
  - Output: Relation: `(Tim Cook, CEO, Apple)`  




## 3. Language Generation & Transformation

### 3.1 Machine Translation
- **Definition**: Translating text from one language to another.  
- **Example**:  
  - Input: `"I love AI."`  
  - Output (Korean): `"나는 인공지능을 사랑한다."`  

### 3.2 Text Summarization
- **Definition**: Producing a concise summary of a longer text.  
- **Types**:  
  - **Extractive Summarization**: Selecting key sentences from the original text.  
  - **Abstractive Summarization**: Generating new sentences that capture the main ideas.  
- **Example**: Summarizing a research paper abstract into two sentences.

### 3.3 Question Answering (QA)
- **Definition**: Extracting or generating answers to questions from a given context.  
- **Example**:  
  - Context: `"Barack Obama was the 44th President of the United States."`  
  - Question: `"Who was the 44th President of the U.S.?"`  
  - Answer: `"Barack Obama"`

### 3.4 Chatbot / Conversational Systems
- **Definition**: Generating coherent and context-aware dialogues with users.  
- **Types**:  
  - **Rule-based Systems**: Predefined patterns.  
  - **Retrieval-based Systems**: Selecting best-matching responses.  
  - **Generative Systems**: Generating responses using deep learning models (e.g., GPT).  
- **Applications**: Customer service, personal assistants, tutoring systems.
