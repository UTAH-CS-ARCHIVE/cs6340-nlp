# [Assignment Report] Naive Bayes for Text Classification

### **Problem: Spam Filtering with Multinomial Naive Bayes**

**Assignment:**
<br>
You are tasked with building a spam filter using the Naive Bayes algorithm. You are given the following small training dataset consisting of four documents, each labeled as either 'Spam' or 'Ham' (not spam).

**Training Data:**
* **Doc 1 (Spam):** "win money now"
* **Doc 2 (Spam):** "free money for you"
* **Doc 3 (Ham):** "play sports now"
* **Doc 4 (Ham):** "sports and fun for you"

Your goal is to classify the following new, unseen document:
* **Test Document:** "free sports money"

You must use **Laplace smoothing** with a smoothing parameter $\alpha = 1$.

**Tasks:**
1.  **Calculate Priors:** Determine the prior probabilities $P(\text{Spam})$ and $P(\text{Ham})$.
2.  **Calculate Smoothed Likelihoods:** For each word in the test document, calculate its Laplace-smoothed probability conditioned on each class. Specifically, find:
    * $P(\text{free} | \text{Spam})$ and $P(\text{free} | \text{Ham})$
    * $P(\text{sports} | \text{Spam})$ and $P(\text{sports} | \text{Ham})$
    * $P(\text{money} | \text{Spam})$ and $P(\text{money} | \text{Ham})$
3.  **Perform Classification:** Calculate the final score for each class using the log-probability version of the Naive Bayes formula.
4.  **Conclusion:** Based on your calculated scores, classify the test document.

<br>

**Solution:**
<br>
**1. Calculate Priors:**
<br>
The prior probability for each class is the fraction of documents in the training set that belong to that class.
* Total number of documents = 4
* Number of 'Spam' documents = 2
* Number of 'Ham' documents = 2

$$
P(\text{Spam}) = \frac{2}{4} = 0.5
$$
$$
P(\text{Ham}) = \frac{2}{4} = 0.5
$$
<br>

**2. Calculate Smoothed Likelihoods:**
<br>
First, we need to define the vocabulary and count the total number of words for each class.
* **Vocabulary (V):** The set of all unique words in the training data.
    $V = \{$ "win", "money", "now", "free", "for", "you", "play", "sports", "and", "fun" $\}$
* **Vocabulary Size ($|V|$):** $|V| = 10$.
* **Total words in 'Spam' docs ($N_{Spam}$):** 3 (from Doc 1) + 4 (from Doc 2) = 7.
* **Total words in 'Ham' docs ($N_{Ham}$):** 3 (from Doc 3) + 5 (from Doc 4) = 8.

The formula for Laplace-smoothed probability is: $P(w|y) = \frac{\text{Count}(w, y) + \alpha}{N_y + \alpha|V|}$. Here, $\alpha = 1$.

* **For the word "free":**
    * Count("free", Spam) = 1
    * Count("free", Ham) = 0
    $$
    P(\text{free} | \text{Spam}) = \frac{1 + 1}{7 + 10} = \frac{2}{17} \approx 0.118
    $$
    $$
    P(\text{free} | \text{Ham}) = \frac{0 + 1}{8 + 10} = \frac{1}{18} \approx 0.056
    $$
* **For the word "sports":**
    * Count("sports", Spam) = 0
    * Count("sports", Ham) = 2
    $$
    P(\text{sports} | \text{Spam}) = \frac{0 + 1}{7 + 10} = \frac{1}{17} \approx 0.059
    $$
    $$
    P(\text{sports} | \text{Ham}) = \frac{2 + 1}{8 + 10} = \frac{3}{18} = \frac{1}{6} \approx 0.167
    $$
* **For the word "money":**
    * Count("money", Spam) = 2
    * Count("money", Ham) = 0
    $$
    P(\text{money} | \text{Spam}) = \frac{2 + 1}{7 + 10} = \frac{3}{17} \approx 0.176
    $$
    $$
    P(\text{money} | \text{Ham}) = \frac{0 + 1}{8 + 10} = \frac{1}{18} \approx 0.056
    $$
<br>

**3. Perform Classification:**
<br>
We calculate the score for each class using the log-probability formula for the test document "free sports money".
$$
\text{Score}(y) = \log P(y) + \sum_{w_i \in \text{doc}} \log P(w_i|y)
$$
* **Score for 'Spam':**
    $$
    \text{Score}(\text{Spam}) = \log(0.5) + \log\left(\frac{2}{17}\right) + \log\left(\frac{1}{17}\right) + \log\left(\frac{3}{17}\right)
    $$
    $$
    \approx -0.693 + (-2.138) + (-2.833) + (-1.735) = -7.399
    $$
* **Score for 'Ham':**
    $$
    \text{Score}(\text{Ham}) = \log(0.5) + \log\left(\frac{1}{18}\right) + \log\left(\frac{3}{18}\right) + \log\left(\frac{1}{18}\right)
    $$
    $$
    \approx -0.693 + (-2.890) + (-1.792) + (-2.890) = -8.265
    $$
<br>

**4. Conclusion:**
<br>
We compare the final scores for each class:
* Score(Spam) $\approx -7.399$
* Score(Ham) $\approx -8.265$

Since the score for 'Spam' is greater (less negative) than the score for 'Ham' ($-7.399 > -8.265$), the Naive Bayes classifier predicts that the test document **"free sports money" is Spam**.